{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Classifying Movie Reviews With IMDB Dataset\n",
    "\n",
    "\n",
    "For this project we'll be using the IMDB dataset for two-class/binary classification. Our goal being to classify movie reviews on being positive or negative based on text content.\n",
    "\n",
    "The IMDB dataset contains 50,000 highly polarized reviews split evenly into 2 groups of 25,000 for training and testing, each group containing 50% positive and 50% negative reviews.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing The Libraries\n",
    "\n",
    "Importing the libraries that will be used for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initial Overview of The Data\n",
    "\n",
    "Train_data and test_data is a list of word indices (encoding a sequence of words). Train_label and test_label are binary lists that indicate whether the review is positive or negative. 0 standing for negative and 1 standing for positive.\n",
    "\n",
    "As for words, we will be restricting ourselves to a max of 10,000 words, these will be the top 10,000 most frequently occuring words in the word indices (as noted when we review for the max sequence in the training dataset which is 9,999).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words to only keep top 10,000 most frequently occuring words\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing first entry in the train data\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first entry in the training labels\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is just a way to decode the review back to English:\n",
    "\n",
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    # Reverses, mapping integer indices to words\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    # Decodes the review (Offset by 3 due to reversed indices used for 'padding', 'start of sequence', and 'unknown')\n",
    "    [reverse_word_index.get(indices-3, '?') for indices in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix in the shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for indices sequence in enumerate(sequences):\n",
    "        # Set specific indices of results[i] to 1s\n",
    "        results[indices, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training data\n",
    "X_train = vectorize_sequences(train_data)\n",
    "# Vectorize test data\n",
    "X_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
